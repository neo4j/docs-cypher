:description: This chapter describes how to use vector indexes to perform approximate nearest neighbor search.

:fn-hnsw: footnote:hnsw[http://dx.doi.org/10.1109/TPAMI.2018.2889473[Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs] -- Yury A. Malkov and Dmitry A. Yashunin (preprint: https://arxiv.org/abs/1603.09320:[arXiv:1603.09320])]
:fn-ieee-754: footnote:ieee-754[https://doi.org/10.1109/IEEESTD.2019.8766229[IEEE Standard for Floating-Point Arithmetic]]

:link-operations-manual: link:{neo4j-docs-base-uri}/operations-manual/{page-version}
:link-procedures-reference: {link-operations-manual}/reference/procedures/

:ieee-754: IEEE 754{fn-ieee-754}

:l2-norm: image:l2.svg["l2"]-norm

[[indexes-vector]]
= Vector search index
_This feature was introduced in Neo4j 5.11._ label:beta[]

This chapter describes how to use vector indexes to perform an approximate nearest neighbor search.

Vector indexes allow users to query vector embeddings from large datasets.
An embedding is a numerical representation of a data object, such as text, image, audio, or document.

For example, each word or token in a text is typically represented as high-dimensional vector where each dimension represents a certain aspect of the wordâ€™s meaning.
Words that are semantically similar or related are often represented by vectors that are closer to each other in this vector space.
This allows for mathematical operations like addition and subtraction to carry semantic meaning.
For example, the vector representation of "king" minus "man" plus "woman" might be close to the vector representation of "queen." 
In other words, vector embeddings can be said to be a numerical representation of a particular data object, capturing its semantic meaning.

The embedding for a particular data object can be generated by for example the https://cloud.google.com/vertex-ai[Vertex AI] or https://openai.com/[OpenAI] embedding generators, which can produce vector embeddings with dimensions 768, 1024, and 1536.
These vector embeddings are stored as `LIST<FLOAT>` properties on a node, where each dimensional component of the vector is an element in the `LIST`.
A Neo4j vector index can be used to index nodes by `LIST<FLOAT>` properties valid to the index.

In Neo4j, a vector index allows you to write queries that match a _neighborhood_ of nodes based on the similarity between the properties of those nodes and the ones specified in the query.

Neo4j vector indexes are powered by the link:https://lucene.apache.org/[Apache Lucene] indexing and search library.
Lucene implements a Hierarchical Navigable Small World{fn-hnsw} (HNSW) Graph to perform a _k_ approximate nearest neighbors (_k_-ANN) query over the vector fields.

== Vector index commands and procedures

Vector indexes are managed through Cypher commands and built-in procedures, see {link-procedures-reference}[Operations Manual -> Procedures] for a complete reference.

The procedures and commands for vector indexes are listed in the following table:

.Commands and procedures for vector indexes
[options="header",cols="3,4a,5a"]
|===
| Usage | Procedure/Command | Description

| Create vector index.
| {link-procedures-reference}#procedure_db_index_vector_createNodeIndex[`db.index.vector.createNodeIndex`]
| Create a named vector index for the given label and property with given vector dimensionality using the given similarity function.

| Use vector index.
| {link-procedures-reference}#procedure_db_index_vector_queryNodes[`db.index.vector.queryNodes`]
| Query the given vector index. Returns the requested number of approximate nearest neighbor nodes and their similarity score, ordered by score.

| Drop vector index.
| `+DROP INDEX index_name+`
| Drop the specified index.

| Listing all vector indexes.
| `SHOW INDEXES WHERE type = "VECTOR"`
| Lists all vector indexes, see the xref:indexes-for-search-performance.adoc#indexes-list-indexes[`SHOW INDEXES`] command for details. There is no vector index filter built into `SHOW INDEXES`.

| Set vector property.
| {link-procedures-reference}#procedure_db_create_setVectorProperty[`db.create.setVectorProperty`]
| Update a given node property with the given vector in a more space-efficient way than directly using xref:clauses/set.adoc#set-set-a-property[`SET`].

|===

[[indexes-vector-create]]
== Create and configure vector indexes

You can create vector indexes using the procedure {link-procedures-reference}#procedure_db_index_vector_createNodeIndex[`db.index.vector.createNodeIndex`].
The name of the index must be unique so that you can reference it when xref:#indexes-vector-query[querying] or if you want to xref:indexes-vector-drop[drop] the index.

[IMPORTANT]
====
The index name must be unique among both indexes and constraints.
====

A vector index is a single-label, single-property index for nodes.
In addition to the label and property key (both given as `STRING`), a vector index needs to be configured with both the dimensionality of the vector (`INTEGER`), and the measure of similarity between two vectors (case-insensitive `STRING`).
For details, see xref:#indexes-vector-similarity[].

.Signature for `db.index.vector.createNodeIndex` to create a vector node index
[source,syntax,role="noheader",indent=0]
----
db.index.vector.createNodeIndex(indexName :: STRING?, label :: STRING?, propertyKey :: STRING?, vectorDimension :: INTEGER?, vectorSimilarityFunction :: STRING?) :: VOID
----

[NOTE]
====
The new index is not immediately available but is created in the background.
====

All vectors within the index must have the same dimensionality.
The measure of similarity is determined by the given vector similarity function.
It defines how similar two vectors are to one another by a similarity score, how vectors are interpreted, and what vectors are valid for the index.

A node is indexed if all the following are true:

* The node contains the configured label.
* The node contains the configured property key.
* The respective property value is of type `LIST<FLOAT>`.
* The xref:functions/scalar.adoc#functions-size[`size()`] of the respective value is the same as the configured dimensionality.
* The value is a valid vector for the configured similarity function.

Otherwise, a node is not indexed.

.Create a vector index
====

For instance, assume you have a graph of research papers, and each paper has an abstract.
You want to find papers in the neighborhood of a paper you know.

.Data model
[source,syntax,role="noheader",indent=0]
----
(:Title)<--(:Paper)-->(:Abstract)
----

Assume for each abstract, you have generated a 1536-dimensional vector `embedding` of the abstract's `text` using Open AI's default model, `text-embedding-ada-002`.
This model suggests a xref:indexes-vector-similarity-cosine[cosine similarity].
For more information, see link:https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use[OpenAI's official documentation].

You can create a cosine vector index over the `embedding` property.

.Query
[source,cypher]
----
CALL db.index.vector.createNodeIndex('abstract-embeddings', 'Abstract', 'embedding', 1536, 'cosine')
----

.Result
[queryResult]
----
(no changes, no records)
----

You can see that the vector index has been created using `SHOW INDEXES`:

.Query
[source,cypher]
----
SHOW INDEXES YIELD name, type, labelsOrTypes, properties, options
WHERE type = "VECTOR"
----

.Result
[role="queryresult",options="header,footer",cols="3m,2m,3m,3m,6m"]
|===

| name | type | labelsOrTypes | properties | options


| "abstract-embeddings" | "VECTOR" | ["Abstract"]  | ["embedding"]
| {indexProvider: "vector-1.0", indexConfig: {vector.dimensions: 1536, vector.similarity_function: "cosine"}}
5+d|Rows: 1

|===

====

[[indexes-vector-query]]
== Query a vector index

You can query a vector index using the procedure {link-procedures-reference}#procedure_db_index_vector_queryNodes[`db.index.vector.queryNodes`].

.Signature for `db.index.vector.queryNodes` to query a vector index
[source,syntax,role="noheader",indent=0]
----
db.index.vector.queryNodes(indexName :: STRING?, numberOfNearestNeighbours :: INTEGER?, query :: LIST? OF FLOAT?) :: (node :: NODE?, score :: FLOAT?)
----

* The `indexName` (a `STRING`) refers to the unique name of the vector index to query.
* The `numberOfNearestNeighbours` (an `INTEGER`) refers to the number of nearest neighbors to return as the neighborhood.
* The `query` vector (a `LIST<FLOAT>`) in which to search for the neighborhood.

The procedure returns the neighborhood of nodes with their respective similarity scores, ordered by those scores.
The scores are bounded between `0` and `1`, where the closer to `1` the score is, the more similar the indexed vector is to the query vector.

.Query a vector index
====
This example takes the paper that describes the HNSW{fn-hnsw} graph structure that the vector index implements and tries to find similar papers.
First you `MATCH` to find the paper, and then you query the `abstract-embeddings` index for a neighborhood of `10` similar abstracts to your query.
Finally, you `MATCH` for the neighborhood's respective titles.

.Query
[source,cypher]
----
MATCH (title:Title)<--(:Paper)-->(abstract:Abstract)
WHERE toLower(title.text) = 'efficient and robust approximate nearest neighbor search using
  hierarchical navigable small world graphs'

CALL db.index.vector.queryNodes('abstract-embeddings', 10, abstract.embedding)
YIELD node AS similarAbstract, score

MATCH (similarAbstract)<--(:Paper)-->(similarTitle:Title)
RETURN similarTitle.text AS title, score
----

.Result
[role="queryresult",options="header,footer",cols="5m,2m"]
|===

| title | score

| "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs"
| 1.0

| "Accelerating Large-Scale Graph-based Nearest Neighbor Search on a Computational Storage Platform"
| 0.9437285661697388

| "Nearest Neighbor Search Under Uncertainty"
| 0.9322342872619629

| "Neighbor selection and hitting probability in small-world graphs"
| 0.9316230416297913

| "Fast Approximate Nearest Neighbor Search With The Navigating Spreading-out Graph"
| 0.9314759373664856

| "Towards Similarity Graphs Constructed by Deep Reinforcement Learning"
| 0.9301378726959229

| "A novel approach to study realistic navigations on networks"
| 0.928106427192688

| "Intentional Walks on Scale Free Small Worlds"
| 0.9274556636810303

| "FINGER: Fast Inference for Graph-based Approximate Nearest Neighbor Search"
| 0.9267876148223877

| "Learning to Route in Similarity Graphs"
| 0.9263730049133301

2+d| Rows: 10

|===

The results are expected, with papers discussing graph-based nearest-neighbor searches.

The most similar to this result is the query vector itself, which is to be expected as the index was queried with an indexed property.
If the query vector itself is not wanted, you can use `WHERE score < 1` to remove equivalent vectors to the query vector.

====

[[indexes-vector-drop]]
== Drop vector indexes

A vector index is dropped by using the xref:indexes-for-search-performance.adoc#indexes-drop-an-index[same command as for other indexes], `DROP INDEX`.

.+DROP INDEX+
======

In the following example, you drop the `abstract-embeddings` that you created previously:

.Query
[source,cypher]
----
DROP INDEX `abstract-embeddings`
----

.Result
[queryresult]
----
Removed 1 index.
----

======

[[indexes-vector-set]]
== Set vector property on a node

You can set a vector property, `LIST<FLOAT>`, on a node using the xref:clauses/set.adoc#set-set-a-property[`SET`] command:

.Syntax for setting a vector property
[source,syntax,role="noheader",indent=0]
----
SET node.propertyKey = vector
----

However, Cypher stores the provided `LIST<FLOAT>` as a primitive array of {ieee-754} _double_ precision values.
Valid vectors for use in the index must have components finitely representable in {ieee-754} _single_ precision.
As a result, it takes up approximately twice as much space.

The {link-procedures-reference}#procedure_db_create_setVectorProperty[`db.create.setVectorProperty`] procedure is provided to validate and set the property as an array of {ieee-754} single precision values.
As a result, the store's space is approximately halved.


.Signature for `db.create.setVectorProperty` to set a vector property
[source,syntax,role="noheader",indent=0]
----
db.create.setVectorProperty(node :: NODE?, key :: STRING?, vector :: LIST? OF FLOAT?) :: (node :: NODE?)
----

Thus, this is the equivalent syntax for setting a vector with a procedure:

.Syntax for setting a vector _via_ a procedure
[source,syntax,role="noheader",indent=0]
----
CALL db.create.setVectorProperty(node, 'propertyKey', vector)
----

This is ideal for creating and setting new vector properties in the graph.
Though existing properties can be re-set using this procedure to minimize store size, there is a cost in transaction log size until they are rotated away, especially in the case of record formats.

[[indexes-vector-similarity]]
== Supported similarity functions

The choice of similarity function can vastly differ in which indexed vectors are considered similar, and which are valid.
The semantic meaning of the vector may itself dictate which similarity function to choose.
Consult the documentation for the particular model used to generate vector embeddings.
The documentation may suggest a preference for certain similarity functions.
Otherwise, understanding the differences between different similarity functions can help make a more informed choice.

.Similarity functions
[%header,cols="d,m,e"]
|===
| Name | Case Insensitive Argument | Key similarity feature

| xref:#indexes-vector-similarity-euclidean[Euclidean]
| "euclidean"
| distance

| xref:indexes-vector-similarity-cosine[Cosine]
| "cosine"
| angle

|===

For {l2-norm}alized vectors (unit vectors), thus their length image:l2norm_is_1.svg["The l2-norm of vector v equals 1"], both Euclidean and cosine similarity functions produce the same similarity ordering.

[[indexes-vector-similarity-euclidean]]
=== Euclidean similarity

Euclidean similarity is useful when the _distance_ between the vectors is what determines how similar two vectors are.

A valid vector for a Euclidean vector index is when all vector components can be represented finitely in {ieee-754} single precision.

Euclidean interprets the vectors in Cartesian coordinates.
The measure is related to the Euclidean distance, how far two points are from one another.
However, that is unbounded, and less useful as a similarity score.
Euclidean similarity bounds the square of Euclidean distance.

image::euclidean_similarity_equation.svg["The Euclidean of vector v and vector u is defined as 1 over the quantity 1 plus the square of the l2-norm of vector v subtract vector u, which exists in the bounded set of real numbers between 0 exclusive and 1 inclusive."]

[[indexes-vector-similarity-cosine]]
=== Cosine similarity

Cosine should be used when the _angle_ between the vectors is what determines how similar two vectors are.

A valid vector for a Cosine vector index is when:

* All vector components can be represented finitely in {ieee-754} single precision.
* And its {l2-norm} is non-zero and can be represented finitely in {ieee-754} single precision.

Cosine interprets the vectors in Cartesian coordinates.
The measure is related to the angle between the two vectors.
However, an angle can be described in many units, sign conventions, and periods.
The trigonometric cosine of this angle is both agnostic to the aforementioned and bounded.
Cosine similarity rebounds the trigonometric cosine.

image::cosine_similarity_equation.svg["The cosine of vector v and vector u is defined as half of the quanity 1 plus the scalar product of v hat u hat, which equals half of the quantity 1 plus the scalar product of vector v vector u over the product of the l2-norm of vector v and the l2 norm ov vector u, which exists in the bounded set of real numbers between 0 inclusive and 1 inclusive."]
The trigonometric in the above equation is given by the scalar product of the two unit vectors.

[[indexes-vector-limitations]]
== Limitations and idiosyncrasies

* The query is an _approximate_ nearest neighbor search.
The requested _k_ nearest neighbors may not be the exact _k_ nearest, but close within the same wider neighborhood, such as finding a local extremum _vs_ the true extremum.

* For large requested nearest neighbors, _k_, close to the total number of indexed vectors, the search may retrieve fewer than _k_ results.

* The index must have a unique name.
There is no provided method for an autogenerated name.

* Only one vector index can be over a schema.
For example, you cannot have one xref:indexes-vector-similarity-euclidean[Euclidean] and one xref:indexes-vector-similarity-cosine[cosine] vector index on the same label-property key pair.

* Only node vector indexes are supported.

* No provided settings or options for tuning the index.

* Changes made within the same transaction are not visible to the index.

* There is no Cypher syntax for creating a vector index, nor for the standard index type filtering with xref:indexes-for-search-performance.adoc#indexes-list-indexes[`SHOW INDEXES`] command.

[[index-vector-issues]]
== Known issues

[%header,cols="5d,d"]
|===
| Known issues | Fixed in

a| xref:clauses/listing-procedures.adoc[`SHOW PROCEDURES`] does not show the vector index procedures:

* {link-procedures-reference}#procedure_db_create_setVectorProperty[`db.create.setVectorProperty`]
* {link-procedures-reference}#procedure_db_index_vector_createNodeIndex[`db.index.vector.createNodeIndex`]
* {link-procedures-reference}#procedure_db_index_vector_queryNodes[`db.index.vector.queryNodes`]
| Neo4j 5.12

| Passing `null` as an argument to some of the procedure parameters can generate a confusing exception.
a| // Neo4j 5.12    pending PR

| The validation for xref:indexes-vector-similarity-cosine[cosine similarity] verifies the vector's {l2-norm} can be represented finitely in {ieee-754} *double* precision, rather than _single_ precision.
This can lead to certain large component vectors being incorrectly indexed, and return a similarity score of `&plusmn;0.0`.
a| // Neo4j 5.12    pending PR

| The vector index `createStatement` field from xref:indexes-for-search-performance.adoc#indexes-list-indexes[`SHOW INDEXES`] does not correctly escape single quotes in index names, labels, and property keys.
a| // Neo4j 5.12    pending PR

a| {link-operations-manual}/backup-restore/copy-database/[Copying a database store] label:enterprise-edition[] with a vector index does not log the recreation command, and instead logs an error:
----
ERROR: [StoreCopy] Unable to format statement for index 'index-name'
----
Due to an:
----
java.lang.IllegalArgumentException: Did not recognize index type VECTOR
----
a| // Neo4j 5.12    pending PR

|===

[[indexes-vector-suggestions]]
== Suggestions

Vector indexes can take advantage of the incubated Java 20 Vector API for noticeable speed improvements.
If you are using a compatible version of Java, you can add the following setting to your {link-operations-manual}/configuration/configuration-settings/#config_server.jvm.additional[configuration settings]:

.Configuration settings
[source,config]
----
server.jvm.additional=--add-modules jdk.incubator.vector
----
