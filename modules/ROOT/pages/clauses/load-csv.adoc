:description: `LOAD CSV` is used to import data from CSV files.

:url_encoded_link: link:https://developer.mozilla.org/en-US/docs/Glossary/percent-encoding[URL-encoded]

[[load-csv]]
= LOAD CSV

[[load-csv-introduction]]
== Introduction

`LOAD CSV` is used to import data from CSV files.

Here is an example where the CSV file _artists.csv_ contains a line index, a name and a year for a number of artists:

.artists.csv
[source, csv, role="noheader", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

The artist data from _artists.csv_ can be read with `LOAD CSV` like this:

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS row
MERGE (:Artist {name: row[1], year: toInteger(row[2])})
----

`FROM` expects a string which represents a URL where the CSV file is located.
It is required to specify a variable for the CSV data using `AS`.
This variable represents the current row while LOAD CSV iterates through the lines of the CSV file.
This way, the data can then be accessed in subsequent clauses.

A new node with the `Artist` label is created for each row in the CSV file.
In addition, values from two columns of the CSV file are set as properties on the nodes.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

Typically, there are three steps in `LOAD CSV` queries:

* Reading CSV data
* Transforming the CSV data
* Creating nodes and relationships from the CSV data

The CSV file format allows for a number of different flavors, for example, using different field delimiters or optional column headers.
CSV files can be read from different sources, and `LOAD CSV` has a mechanism for handling large amounts of data.

It is entirely possible to import data from multiple CSV files with multiple `LOAD CSV` queries.
Each data set can be transformed as needed in the process, preparing for the creation of nodes and relationships.
Since all CSV data imported via `LOAD CSV` is string data, a common transformation is type casting to specific data types.

[NOTE]
====
`LOAD CSV` is regulated by the link:{neo4j-docs-base-uri}/operations-manual/{page-version}/authentication-authorization/load-privileges/[load privileges].
====

[[load-csv-file-format]]
== CSV file format

The Wikipedia article on link:https://en.wikipedia.org/wiki/Comma-separated_values[Comma-separated values] summarizes why there are different flavors of the CSV format.

A CSV file to use with `LOAD CSV` must have UTF-8 as its character encoding.
The line terminator is system-dependent, for example, it is `\n` for Unix and `\r\n` for Windows.

[[load-csv-headers]]
=== Headers

If the CSV file starts with a header row containing column names, each subsequent row in the file acts as a map instead of an array of strings when imported:

.artists-with-headers.csv
[source, csv, filename="artists-with-headers.csv"]
----
Id,Name,Year
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

Indicate the header row by adding `WITH HEADERS` to the query.
This way, you can access specific fields by their corresponding column name:

.Query
[source, cypher]
----
LOAD CSV WITH HEADERS FROM 'file:///artists-with-headers.csv' AS row
MERGE (:Artist {name: row.Name, year: toInteger(row.Year)})
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

[[load-csv-field-delimiter]]
=== Field delimiter

The default field delimiter is `,`.
A CSV file may have other field delimiters:

.artists-fieldterminator.csv
[source, csv, role="noheaders", filename="artists-fieldterminator.csv"]
----
1;ABBA;1992
2;Roxette;1986
3;Europe;1979
4;The Cardigans;1992
----

In that case, change the field delimiter character by using the optional `FIELDTERMINATOR` in your query:

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists-fieldterminator.csv' AS row FIELDTERMINATOR ';'
MERGE (:Artist {name: row[1], year: toInteger(row[2])})
----

As values in this file are separated by a semicolon, a custom `FIELDTERMINATOR` is specified in the `LOAD CSV` clause.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

[NOTE]
====
You can use the hexadecimal representation of the unicode character for the field delimiter if you prepend `{backslash}u`.
Write the encoding with four digits, for example, `{backslash}u003B` is equivalent to `;` (semicolon).
====


[[load-csv-character-escaping-and-quotes]]
=== Character escaping and quotes

If the link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings[configuration setting] `dbms.import.csv.legacy_quote_escaping` is set to `true` (the default value), `\` is used as the escape character: `"The {backslash}"Symbol{backslash}""`.
The inner double quote characters are escaped, leaving them unprocessed by `LOAD CSV`.
For the double quote character, you can achieve the same thing by repeating it - the escape sequence above is equivalent to `"The ""Symbol"""`.

Quoted strings are allowed in the CSV file and the quotes are dropped when reading the data with `LOAD CSV`.
To apply quotation to a string, wrap it with double quote characters: `"my_string"`.

The example below has both additional quotes around each value as well as escaped quotes in the second value:

.artists-with-escaped-char.csv
[source, csv, role="noheaders", filename="artists-with-escaped-char.csv"]
----
"1","The ""Symbol""","1992"
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists-with-escaped-char.csv' AS row
MERGE (a:Artist {name: row[1], year: toInteger(row[2])})
RETURN
  a.name AS name,
  a.year AS year,
  size(a.name) AS size
----

Note that `name` is a string and that it is wrapped in single quotes in the output below.
The third column outputs the string length as `size`.
The length only counts what is between the single quotes, but not the quotes themselves:

.Result
[role="queryresult",options="header,footer",cols="3*<m"]
|===
| name | year | size
| 'The "Symbol"' | 1992 | 12
3+d| Nodes created: 1 +
Properties set: 2 +
Labels added: 1
|===

[[load-csv-access-line-numbers-with-linenumber]]
=== Access line numbers with `linenumber()`

For certain scenarios, like debugging a problem with a CSV file, it may be useful to get the current line number which `LOAD CSV` is operating on.
The `linenumber()` function provides exactly that or `null` if called without a `LOAD CSV` context.

.artists.csv
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS row
RETURN linenumber() AS number, row
----

.Result
[role="queryresult"]
----
+---------------------------------------+
| number | row                          |
+---------------------------------------+
| 1      | ["1","ABBA","1992"]          |
| 2      | ["2","Roxette","1986"]       |
| 3      | ["3","Europe","1979"]        |
| 4      | ["4","The Cardigans","1992"] |
+---------------------------------------+
4 rows
----

Also see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/functions/load-csv/#functions-linenumber[linenumber()] under LOAD CSV functions.


[[load-csv-access-the-csv-file-path-with-file]]
=== Access the CSV file path with `file()`

For certain scenarios, it may be useful to get the absolute path of the file that `LOAD CSV` is operating on.
The `file()` function provides exactly if it is called in a `LOAD CSV` context (`null` otherwise).

.artists.csv
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher, role=test-result-skip]
----
LOAD CSV FROM 'file:///artists.csv' AS row
RETURN DISTINCT file() AS path
----

Since `LOAD CSV` can temporary download a file to process it, it is important to note that `file()` will always return the path on disk.
If `LOAD CSV` is invoked with a `file:///` URL that points to your disk `file()` will return that same path.

.Result
[role="queryresult"]
----
+------------------------------------------+
| path                                     |
+------------------------------------------+
| "/home/example/neo4j/import/artists.csv" |
+------------------------------------------+
1 row
----

Also see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/functions/load-csv/#functions-file[file()] under LOAD CSV functions.


[[load-csv-get-csv-data-into-neo4j]]
== Get CSV data into Neo4j

The following sections summarize where CSV files may be located for the import via `LOAD CSV`, how `LOAD CSV` can handle large amounts of data, how to type cast CSV string data in Neo4j and other data transformations and how to create nodes and relationships from the data.


[[load-csv-file-location]]
=== CSV file location

You can store CSV files on the database server and then access them by using a `+file:///+` URL, depending on the configuration settings:

.Configuration settings for file URLs
link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings#config_dbms.security.allow_csv_import_from_file_urls[dbms.security.allow_csv_import_from_file_urls]::
This setting determines if Cypher allows the use of `+file:///+` URLs when loading data using `LOAD CSV`.
Such URLs identify files on the filesystem of the database server.
Default is _true_.
Setting `dbms.security.allow_csv_import_from_file_urls=false` will completely disable access to the file system for `LOAD CSV`.

link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings#config_server.directories.import[server.directories.import]::
Sets the root directory for `+file:///+` URLs used with the Cypher `LOAD CSV` clause.
This should be set to a single directory relative to the Neo4j installation path on the database server.
All requests to load from `+file:///+` URLs are then relative to the specified directory.
The default value set in the config settings is _import_.
This is a security measure which prevents the database from accessing files outside the standard link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/file-locations[import directory],
similar to how a Unix `chroot` operates.
Setting this to an empty field allows access to all files within the Neo4j installation folder.
Commenting out this setting disables the security feature, allowing all files in the local system to be imported.
This is definitely not recommended.

File URLs are resolved relative to the `server.directories.import` directory.
For example, a file URL typically looks like `+file:///myfile.csv+` or `+file:///myproject/myfile.csv+`.

When using `+file:///+` URLs, spaces and other non-alphanumeric characters must be {url_encoded_link}.
If `server.directories.import` is set to the default value _import_, using the above URLs in `LOAD CSV` would read from _<NEO4J_HOME>/import/myfile.csv_ and _<NEO4J_HOME>/import/myproject/myfile.csv_ respectively.
*  If it is set to _/data/csv_, using the above URLs in `LOAD CSV` would read from _<NEO4J_HOME>/data/csv/myfile.csv_ and _<NEO4J_HOME>/data/csv/myproject/myfile.csv_ respectively.

Alternatively, you can import data from a CSV file in a remote location into Neo4j:

.data.neo4j.com/bands/artists.csv
[source, csv, role="noheader", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/bands/artists.csv' AS row
MERGE (:Artist {name: row[1], year: toInteger(row[2])})
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

`LOAD CSV` supports accessing CSV files via _HTTPS_, _HTTP_, and _FTP_.
`LOAD CSV` will follow _HTTP_ redirects but for security reasons it won't follow redirects which change the protocol, for example, if the redirect is going from _HTTPS_ to _HTTP_.

[NOTE]
====
The file location is relative to the import.
The config setting `server.directories.import` only applies to a local disc but doesn't to remote URLs.
====

`LOAD CSV` supports resources compressed with _gzip_ and _Deflate_.
Additionally `LOAD CSV` supports locally stored CSV files compressed with _ZIP_.


[[load-csv-large-amounts-of-data]]
=== Large amounts of data

If the CSV file contains a significant number of rows approaching hundreds of thousands or millions, we recommend you to serialize the data processing and reduce memory overhead by doing so.
You can achieve this via link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/subqueries/subqueries-in-transactions/[multiple transactions of subqueries].
The syntax for this is `+CALL { ... } IN TRANSACTIONS+` which instructs Neo4j to commit a transaction after a number of rows.
The default is 1000 rows.
To set a different number of rows for a single transaction, append `+OF X ROWS` to `TRANSACTIONS`, where `X` is the desired number of rows.


[NOTE]
====
The query clause `CALL { ... } IN TRANSACTIONS` is only allowed in xref::introduction/cypher_neo4j.adoc#cypher-neo4j-transactions[implicit (auto-commit or `:auto`) transactions].
For more information, see xref:subqueries/subqueries-in-transactions.adoc[Subqueries in transactions].
====

The file link:https://data.neo4j.com/importing-cypher/persons.csv[_persons.csv_] contains a header line and a total of 869 lines with data about people:

.+persons.csv+
[source, csv, filename="persons.csv"]
----
person_tmdbId,bio,born,bornIn,died,person_imdbId,name,person_poster,person_url
3,"Legendary Hollywood Icon Harrison Ford was born on July 13, 1942 in Chicago, Illinois.   His family history includes a strong lineage of actors, radio personalities, and models.   Harrison attended public high school in Park Ridge, Illinois where he was a member of the school Radio Station WMTH.  Harrison worked as the lead voice for sports reporting at WMTH for several years.   Acting wasn’t a major interest to Ford until his junior year at Ripon College when he first took an acting class...",1942-07-13,"Chicago, Illinois, USA",,148,Harrison Ford,https://image.tmdb.org/t/p/w440_and_h660_face/5M7oN3sznp99hWYQ9sX0xheswWX.jpg,https://themoviedb.org/person/3
...
----

The file is more complex than the previous examples throughout this chapter.
For now, only the `name` and `born` columns are relevant.
To split the processing into chunks of 200 lines per transaction, use the following query:

.Query
[source, cypher]
----
CALL {
  LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/persons.csv' AS row
  MERGE (p:Person)
  SET
  p.tmdbId = row.tmdbId,
  p.name = row.name,
  p.born = row.born
} IN TRANSACTIONS OF 200 ROWS
----

With a total of five transactions, Neo4j creates 868 `Person` nodes and sets three properties on each of them: an ID, a name and information about when the person was born.

Note that the query doesn't import the data from all columns.
It's perfectly valid to just import a part of the data.
In some cases, this may be intended or feasible, depending on the data model prior to the import and what the goal is after the import.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 868
Properties set: 2604
Labels added: 868
Transactions committed: 5
----


[[load-csv-type-cast-csv-data]]
=== Type cast CSV data

All CSV data imported via `LOAD CSV` is string data.
The file link:https://data.neo4j.com/importing-cypher/persons.csv[_persons.csv_] contains several columns which are not best represented by a string:

.+persons.csv+
[source, csv, filename="persons.csv"]
----
person_tmdbId,bio,born,bornIn,died,person_imdbId,name,person_poster,person_url
3,"Legendary Hollywood Icon Harrison Ford was born on July 13, 1942 in Chicago, Illinois.   His family history includes a strong lineage of actors, radio personalities, and models.   Harrison attended public high school in Park Ridge, Illinois where he was a member of the school Radio Station WMTH.  Harrison worked as the lead voice for sports reporting at WMTH for several years.   Acting wasn’t a major interest to Ford until his junior year at Ripon College when he first took an acting class...",1942-07-13,"Chicago, Illinois, USA",,148,Harrison Ford,https://image.tmdb.org/t/p/w440_and_h660_face/5M7oN3sznp99hWYQ9sX0xheswWX.jpg,https://themoviedb.org/person/3
...
----

Values in the column `person_tmdbId` are integers, while values in the `born` column are dates.
To type-cast the values while importing data, use the functions `toInteger()` and `date()`:

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/persons.csv' AS row
MERGE (p:Person)
SET
p.tmdbId = toInteger(row.tmdbId),
p.name = row.name,
p.born = date(row.born)
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 868
Properties set: 2604
Labels added: 868
----

Neo4j has many more link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/values-and-types/casting-data/[type-casting functions].
See link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/functions/temporal/#functions-date[date()] and subsequent sections for more information about time-related type casting.


[[load-csv-split-list-values]]
=== Split list values

The file link:https://data.neo4j.com/importing-cypher/movies.csv[_movies.csv_] contains a header line and a total of 94 lines with data about movies.
Two columns contain list values, `languages` and `genres`:

.+movies.csv+
[source, csv, filename="movies.csv"]
----
movieId,title,budget,countries,movie_imdbId,imdbRating,imdbVotes,languages,plot,movie_poster,released,revenue,runtime,movie_tmdbId,movie_url,year,genres
1,Toy Story,30000000.0,USA,114709,8.3,591836,English,A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.,https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg,1995-11-22,373554033.0,81,862,https://themoviedb.org/movie/862,1995,Adventure|Animation|Children|Comedy|Fantasy
2,Jumanji,65000000.0,USA,113497,6.9,198355,English|French,"When two kids find and play a magical board game, they release a man trapped for decades in it and a host of dangers that can only be stopped by finishing the game.",https://image.tmdb.org/t/p/w440_and_h660_face/vgpXmVaVyUL7GGiDeiK1mKEKzcX.jpg,1995-12-15,262797249.0,104,8844,https://themoviedb.org/movie/8844,1995,Adventure|Children|Fantasy
...
----

Both lists are separated by the character `|`.
Use the `split()` function to separate the single values and create a list while importing the data:

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/movies.csv' AS row
MERGE (m:Movie)
SET
m.movieId = toInteger(row.movieId),
m.title = row.title,
m.imdbId = toInteger(row.movie_imdbId),
m.languages = split(row.languages, '|'),
m.genres = split(row.genres, '|')
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 93
Properties set: 465
Labels added: 93
----

Also see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/functions/string/[String functions] for more options to work with string data.


[[load-csv-create-relationships]]
=== Create relationships

The next query builds upon the person and movie nodes created in <<load-csv-type-cast-csv-data>> and <<load-csv-split-list-values>>.
It makes use of the additional CSV file link:https://data.neo4j.com/importing-cypher/acted_in.csv[_acted_in.csv_].

_acted_in.csv_ contains data about the relationship between actors and the movies they acted in.
The connection between actors and movies is established by the properties `person_tmdbId` and `movieId`:

.+movies.csv+
[source, csv, filename="acted_in.csv"]
----
movieId,person_tmdbId,role
1,12899,Slinky Dog (voice)
1,12898,Buzz Lightyear (voice)
...
----

_movies.csv_ also holds the role the actor played in the movie.

The data are deliberately modeled like they could have been exported from a relational database.
The table represented by _acted_in.csv_ acts as a look-up table combining the primary keys, the IDs, of the tables represented by _persons.csv_ and _movies.csv_.

The following query creates the `ACTED_IN` relationship:

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/acted_in.csv' AS row
MATCH (p:Person {tmdbId: toInteger(row.person_tmdbId)})
MATCH (m:Movie {movieId: toInteger(row.movieId)})
MERGE (p)-[r:ACTED_IN]->(m)
SET r.role = row.role
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Relationships created: 372
Properties set: 372
----


[[load-csv-best-practices]]
== Best practices

This section summarizes some best practices while using `LOAD CSV`.


[[load-csv-create-constraints]]
=== Create CONSTRAINTS

The CSV files _persons.csv_ and _movies.csv_ processed in <<load-csv-type-cast-csv-data>>, <<load-csv-split-list-values>> and <<load-csv-create-relationships>> both contain IDs for the created nodes.
They uniquely identify a person or a movie node but so far there is no check if they are truly unique.
Neo4j's concept of constraints is a way of enforcing uniqueness.

To create link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/constraints/examples/#constraints-examples-node-uniqueness[node property uniqueness constraints] for the two IDs:

.Query
[source, cypher]
----
CREATE CONSTRAINT Person_tmdbId IF NOT EXISTS
FOR (p:Person)
REQUIRE p.tmdbId IS UNIQUE

CREATE CONSTRAINT Movie_movieId IF NOT EXISTS
FOR (m:Movie)
REQUIRE m.movieId IS UNIQUE
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Added 2 constraints.
----

Now that there are uniqueness constraints, trying to create a person node with an existing `tmdbId` or a movie node with an existing `movieId` raises an error and doesn't create the node.

Note that creating constraints after importing data is risky, since the creation of a constraint fails if there are nodes or relationship that would violate the constraint, see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/constraints/examples/#constraints-fail-to-create-a-uniqueness-constraint-due-to-conflicting-nodes[Creating a constraint when there exist conflicting nodes will fail].
Therefore, it is recommend to create constraints prior to importing data.

There are many more link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/constraints/[types of constraints].


[[load-csv-create-additional-node-labels]]
=== Create additional node labels

The `ACTED_IN` relationship created in <<load-csv-create-relationships>> implicitly defines actors as a subset of people in _persons.csv_.
To apply an additional actor node label where it is applicable, based on the relationship:

.Query
[source, cypher]
----
MATCH (p:Person)-[:ACTED_IN]->()
WITH DISTINCT p SET p:Actor
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Labels added: 104
----

By adding the `Actor` label to the relevant person nodes, queries which target the label rather than the relationship are quicker to return, see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/appendix/tutorials/basic-query-tuning/[Basic query tuning].


[[load-csv-build-an-import-process]]
=== Build an import process

Generally speaking, data import is a process where the first attempts might not immediately succeed.
It's perfectly valid to start out with a basic import query, build upon it and increase its complexity.

A couple of techniques can facilitate the trial and error process towards data import via `LOAD CSV`.
While working towards `LOAD CSV` queries which satisfy your requirements for data import and data modeling, it is useful to keep track of what you're doing, clean up intermediate steps and reproduce easily what you achieved so far.

You can always inspect nodes and relationships via `MATCH` and `RETURN`.

Similarly, you can reset all data by running a series of DELETE and DROP queries:

.Query
[source, cypher]
----
MATCH (p:Person) DETACH DELETE p;
MATCH (m:Movie) DETACH DELETE m;

DROP CONSTRAINT Person_tmdbId IF EXISTS;
DROP CONSTRAINT Movie_movieId IF EXISTS;
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Deleted 961 nodes, deleted 372 relationships.
Removed 2 constraints.
----

Note that you can combine multiple queries with a semicolon `;`.

Deletion and creation can be combined into a single process consisting of multiple Cypher queries:

.Query
[source, cypher]
----
MATCH (p:Person) DETACH DELETE p;
MATCH (m:Movie) DETACH DELETE m;

DROP CONSTRAINT Person_tmdbId IF EXISTS;
DROP CONSTRAINT Movie_movieId IF EXISTS;

CREATE CONSTRAINT Person_tmdbId IF NOT EXISTS
FOR (p:Person)
REQUIRE p.tmdbId IS UNIQUE

CREATE CONSTRAINT Movie_movieId IF NOT EXISTS
FOR (m:Movie)
REQUIRE m.movieId IS UNIQUE

LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/persons.csv' AS row
MERGE (p:Person)
SET
p.tmdbId = toInteger(row.tmdbId),
p.name = row.name,
p.born = date(row.born);

LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/movies.csv' AS row
MERGE (m:Movie)
SET
m.movieId = toInteger(row.movieId),
m.title = row.title,
m.imdbId = toInteger(row.movie_imdbId),
m.languages = split(row.languages, '|'),
m.genres = split(row.genres, '|');

LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/acted_in.csv' AS row
MATCH (p:Person {tmdbId: toInteger(row.person_tmdbId)})
MATCH (m:Movie {movieId: toInteger(row.movieId)})
MERGE (p)-[r:ACTED_IN]->(m)
SET r.role = row.role;

MATCH (p:Person)-[:ACTED_IN]->()
WITH DISTINCT p SET p:Actor;
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Added 2 constraints.
Nodes created: 961
Relationships created: 372
Properties set: 3441
Labels added: 1065
----

The example above combines the queries from sections <<load-csv-type-cast-csv-data>>, <<load-csv-split-list-values>>, <<load-csv-create-relationships>>, <<load-csv-create-constraints>> and <<load-csv-create-additional-node-labels>>.

You can run this query at any point to refresh the database with the latest data.
A single process to build your graph provides a consistent mechanism to test your import.


[[load-csv-further-reading]]
== Further reading

link:https://neo4j.com/docs/getting-started/data-modeling/guide-data-modeling/[Data modeling] considerations are relevant for the data import via `LOAD CSV` as well.
The imported data may not be optimized for graph database usage and it may be worthwhile to think about what options there are to make full use of Neo4j's feature set.

Furthermore, nodes and relationshops in the resulting graph database can be made more accessible and supportive towards query optimization.
link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/indexes/[Node indexes] can vastly speed up queries. Also see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/appendix/tutorials/basic-query-tuning/[Basic query tuning].

Finally, link:https://neo4j.com/docs/getting-started/data-import/csv-import/[Importing CSV data into Neo4j] covers some more aspects of working with CSV files without the heavy focus on Cypher's `LOAD CSV` clause.