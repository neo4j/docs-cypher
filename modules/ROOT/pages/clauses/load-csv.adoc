:description: `LOAD CSV` is used to import data from CSV files.

:url_encoded_link: link:https://developer.mozilla.org/en-US/docs/Glossary/percent-encoding[URL-encoded]

[[load-csv]]
= LOAD CSV

[[load-csv-introduction]]
== Introduction

`LOAD CSV` is used to import data from CSV files.

Here is an example where the CSV file _artists.csv_ contains an index, a name and a year for a number of artists:

.artists.csv
[source, csv, role="noheader", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

The artist data from _artists.csv_ can be read with `LOAD CSV` like this:

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS line
CREATE (:Artist {name: line[1], year: toInteger(line[2])})
----

`FROM` expects a string which represents a URL where the CSV file is located.
It is required to specify a variable for the CSV data using `AS`.
This variable represents the current line while LOAD CSV iterates through the lines of the CSV file.
This way, the data can then be accessed in subsequent clauses.

A new node with the `Artist` label is created for each row in the CSV file.
In addition, values from two columns of the CSV file are set as properties on the nodes.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

Typically, there are three steps in `LOAD CSV` queries:

* Reading CSV data
* Transforming the CSV data
* Creating nodes and relationships from the CSV data

The CSV file format allows for a number of different flavors, for example, using different field delimiters or optional column headers.
CSV files can be read from different sources, and `LOAD CSV` has a mechanism for handling large amounts of data.

It is entirely possible to import data from multiple CSV files with multiple `LOAD CSV` queries.
Each data set can be transformed as needed in the process, preparing for the creation of nodes and relationships.
Since all CSV data imported via `LOAD CSV` is string data, a common transformation is type casting to specific data types.

See the following sections for details on these topics.

[NOTE]
====
`LOAD CSV` is regulated by the link:{neo4j-docs-base-uri}/operations-manual/{page-version}/authentication-authorization/load-privileges/[load privileges].
====

[[load-csv-file-format]]
== CSV file format

The Wikipedia article on link:https://en.wikipedia.org/wiki/Comma-separated_values[Comma-separated values] summarizes why there are different flavors of the CSV format.

A CSV file to use with `LOAD CSV` must have UTF-8 as its character encoding.
The line terminator is system-dependent, e.g., it is `\n` for Unix and `\r\n` for Windows.

[[load-csv-headers]]
=== Headers

If the CSV file starts with a header row containing column names, each subsequent row in the file acts as a map instead of an array of strings:

.artists-with-headers.csv
[source, csv, role="noheaders", filename="artists-with-headers.csv"]
----
Id,Name,Year
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

Indicate the header row by adding `WITH HEADERS` to the query.
This way, you can access specific fields by their corresponding column name:

.Query
[source, cypher]
----
LOAD CSV WITH HEADERS FROM 'file:///artists-with-headers.csv' AS line
CREATE (:Artist {name: line.Name, year: toInteger(line.Year)})
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

[[load-csv-field-delimiter]]
=== Field delimiter

The default field delimiter is `,`.
A CSV file may have other field delimiters:

.artists-fieldterminator.csv
[source, csv, role="noheaders", filename="artists-fieldterminator.csv"]
----
1;ABBA;1992
2;Roxette;1986
3;Europe;1979
4;The Cardigans;1992
----

In that case, change the field delimiter character by using the optional `FIELDTERMINATOR` in your query:

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists-fieldterminator.csv' AS line FIELDTERMINATOR ';'
CREATE (:Artist {name: line[1], year: toInteger(line[2])})
----

As values in this file are separated by a semicolon, a custom `FIELDTERMINATOR` is specified in the `LOAD CSV` clause.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

[NOTE]
====
You can use the hexadecimal representation of the unicode character for the field delimiter if you prepend `{backslash}u`.
Write the encoding with four digits, for example, `{backslash}u003B` is equivalent to `;` (semicolon).
====


[[load-csv-character-escaping-and-quotes]]
=== Character escaping and quotes

If the link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings[configuration setting] `dbms.import.csv.legacy_quote_escaping` is set to `true` (the default value), `\` is used as the escape character: `"The {backslash}"Symbol{backslash}""`.
The inner double quote characters are escaped, leaving them unprocessed by `LOAD CSV`.
Only for the double quote character, you can achieve the same thing by repeating it - the escape sequence above is equivalent to `"The ""Symbol"""`.

Quoted strings are allowed in the CSV file and the quotes are dropped when reading the data with `LOAD CSV`.
To apply quotation to a string, wrap it with double quote characters: `"my_string"`.

The example below has both additional quotes around each value as well as escaped quotes in the second value:

.artists-with-escaped-char.csv
[source, csv, role="noheaders", filename="artists-with-escaped-char.csv"]
----
"1","The ""Symbol""","1992"
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists-with-escaped-char.csv' AS line
CREATE (a:Artist {name: line[1], year: toInteger(line[2])})
RETURN
  a.name AS name,
  a.year AS year,
  size(a.name) AS size
----

Note that `name` is a string and that it is wrapped in single quotes in the output below.
The third column outputs the string length as `size`.
The length only counts what is between the single quotes, but not the quotes themselves:

.Result
[role="queryresult",options="header,footer",cols="3*<m"]
|===
| name | year | size
| 'The "Symbol"' | 1992 | 12
3+d| Nodes created: 1 +
Properties set: 2 +
Labels added: 1
|===

[[load-csv-access-line-numbers-with-linenumber]]
=== Access line numbers with `linenumber()`

For certain scenarios, like debugging a problem with a CSV file, it may be useful to get the current line number that `LOAD CSV` is operating on.
The `linenumber()` function provides exactly that or `null` if called without a `LOAD CSV` context.

.artists.csv
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS line
RETURN linenumber() AS number, line
----

.Result
[role="queryresult"]
----
+---------------------------------------+
| number | line                         |
+---------------------------------------+
| 1      | ["1","ABBA","1992"]          |
| 2      | ["2","Roxette","1986"]       |
| 3      | ["3","Europe","1979"]        |
| 4      | ["4","The Cardigans","1992"] |
+---------------------------------------+
4 rows
----


[[load-csv-access-the-csv-file-path-with-file]]
=== Access the CSV file path with `file()`

For certain scenarios, it may be useful to get the absolute path of the file that `LOAD CSV` is operating on.
The `file()` function provides exactly if it is called in a `LOAD CSV` context (`null` otherwise).

.artists.csv
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher, role=test-result-skip]
----
LOAD CSV FROM 'file:///artists.csv' AS line
RETURN DISTINCT file() AS path
----

Since `LOAD CSV` can temporary download a file to process it, it is important to note that `file()` will always return the path on disk.
If `LOAD CSV` is invoked with a `file:///` URL that points to your disk `file()` will return that same path.

.Result
[role="queryresult"]
----
+------------------------------------------+
| path                                     |
+------------------------------------------+
| "/home/example/neo4j/import/artists.csv" |
+------------------------------------------+
1 row
----


[[load-csv-get-csv-data-into-neo4j]]
== Get CSV data into Neo4j

[[load-csv-data-sources]]
=== CSV data sources

You can store CSV files on the database server and then access them by using a `+file:///+` URL, depending on the configuration settings.

// How to store them?

.Configuration settings for file URLs
link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings#config_dbms.security.allow_csv_import_from_file_urls[dbms.security.allow_csv_import_from_file_urls]::
This setting determines if Cypher allows the use of `+file:///+` URLs when loading data using `LOAD CSV`.
Such URLs identify files on the filesystem of the database server.
Default is _true_.
Setting `dbms.security.allow_csv_import_from_file_urls=false` will completely disable access to the file system for `LOAD CSV`.

link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings#config_server.directories.import[server.directories.import]::
Sets the root directory for `+file:///+` URLs used with the Cypher `LOAD CSV` clause.
This should be set to a single directory relative to the Neo4j installation path on the database server.
All requests to load from `+file:///+` URLs are then relative to the specified directory.
The default value set in the config settings is _import_.
This is a security measure which prevents the database from accessing files outside the standard link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/file-locations[import directory],
similar to how a Unix `chroot` operates.
Setting this to an empty field allows access to all files within the Neo4j installation folder.
Commenting out this setting disables the security feature, allowing all files in the local system to be imported.
This is definitely not recommended.

File URLs are resolved relative to the `server.directories.import` directory.
For example, a file URL typically looks like `+file:///myfile.csv+` or `+file:///myproject/myfile.csv+`.

When using `+file:///+` URLs, spaces and other non-alphanumeric characters must be {url_encoded_link}.
If `server.directories.import` is set to the default value _import_, using the above URLs in `LOAD CSV` would read from _<NEO4J_HOME>/import/myfile.csv_ and _<NEO4J_HOME>/import/myproject/myfile.csv_ respectively.
*  If it is set to _/data/csv_, using the above URLs in `LOAD CSV` would read from _<NEO4J_HOME>/data/csv/myfile.csv_ and _<NEO4J_HOME>/data/csv/myproject/myfile.csv_ respectively.

.data.neo4j.com/bands/artists.csv
[source, csv, role="noheader", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/bands/artists.csv' AS line
CREATE (:Artist {name: line[1], year: toInteger(line[2])})
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----


Alternatively, you can import data from a CSV file in a remote location into Neo4j.
`LOAD CSV` supports accessing CSV files via _HTTPS_, _HTTP_, and _FTP_.
`LOAD CSV` will follow _HTTP_ redirects but for security reasons it won't follow redirects which change the protocol, for example, if the redirect is going from _HTTPS_ to _HTTP_.
//Example

[NOTE]
====
The file location is relative to the import.
The config setting `server.directories.import` only applies to a local disc but doesn't to remote URLs.
====

`LOAD CSV` supports resources compressed with _gzip_ and _Deflate_.
Additionally `LOAD CSV` supports locally stored CSV files compressed with _ZIP_.
//Add links


[[load-csv-large-amounts-of-data]]
=== Large amounts of data

If the CSV file contains a significant number of rows approaching hundreds of thousands or millions, we recommend you to serialize the processing.
You can achieve this via link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/subqueries/subqueries-in-transactions/[multiple transactions of subqueries].
`+CALL { ... } IN TRANSACTIONS+` can be used to instruct Neo4j to commit a transaction after a number of rows.
This reduces the memory overhead of the transaction state.

[NOTE]
====
The query clause `CALL { ... } IN TRANSACTIONS` is only allowed in xref::introduction/cypher_neo4j.adoc#cypher-neo4j-transactions[implicit (auto-commit or `:auto`) transactions].
For more information, see xref:subqueries/subqueries-in-transactions.adoc[Subqueries in transactions].
====

// better example

.+artists.csv+
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS line
CALL {
  WITH line
  CREATE (:Artist {name: line[1], year: toInteger(line[2])})
} IN TRANSACTIONS OF 500 ROWS
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
Transactions committed: 1
----

You can set the number of rows as in the example, where it is set to `500` rows.



[[load-csv-type-cast-csv-data]]
=== Type cast CSV data

Lipsum.


[[load-csv-split-list-values]]
=== Split list values

Lipsum.


[[load-csv-create-nodes-and-relationships]]
=== Create nodes and relationships

Lipsum.


[[load-csv-best-practices]]
== Best practices

Lipsum.


[[load-csv-inspect-imported-data-with-match]]
=== Inspect imported data with MATCH

Lipsum.


[[load-csv-prepare-clean-up-queries]]
=== Prepare clean-up queries

Lipsum.


[[load-csv-set-constraints]]
=== Set CONSTRAINTS

Lipsum.