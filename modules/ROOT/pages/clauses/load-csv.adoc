:description: `LOAD CSV` is used to import data from CSV files.

:url_encoded_link: link:https://developer.mozilla.org/en-US/docs/Glossary/percent-encoding[URL-encoded]

[[load-csv]]
= LOAD CSV

[[load-csv-introduction]]
== Introduction

`LOAD CSV` is used to import data from CSV files.

Here is an example where the CSV file _artists.csv_ contains an index, a name and a year for a number of artists:

.artists.csv
[source, csv, role="noheader", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

The artist data from _artists.csv_ can be read with `LOAD CSV` like this:

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS row
CREATE (:Artist {name: row[1], year: toInteger(row[2])})
----

`FROM` expects a string which represents a URL where the CSV file is located.
It is required to specify a variable for the CSV data using `AS`.
This variable represents the current row while LOAD CSV iterates through the lines of the CSV file.
This way, the data can then be accessed in subsequent clauses.

A new node with the `Artist` label is created for each row in the CSV file.
In addition, values from two columns of the CSV file are set as properties on the nodes.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

Typically, there are three steps in `LOAD CSV` queries:

* Reading CSV data
* Transforming the CSV data
* Creating nodes and relationships from the CSV data

The CSV file format allows for a number of different flavors, for example, using different field delimiters or optional column headers.
CSV files can be read from different sources, and `LOAD CSV` has a mechanism for handling large amounts of data.

It is entirely possible to import data from multiple CSV files with multiple `LOAD CSV` queries.
Each data set can be transformed as needed in the process, preparing for the creation of nodes and relationships.
Since all CSV data imported via `LOAD CSV` is string data, a common transformation is type casting to specific data types.

See the following sections for details on these topics.

[NOTE]
====
`LOAD CSV` is regulated by the link:{neo4j-docs-base-uri}/operations-manual/{page-version}/authentication-authorization/load-privileges/[load privileges].
====

[[load-csv-file-format]]
== CSV file format

The Wikipedia article on link:https://en.wikipedia.org/wiki/Comma-separated_values[Comma-separated values] summarizes why there are different flavors of the CSV format.

A CSV file to use with `LOAD CSV` must have UTF-8 as its character encoding.
The line terminator is system-dependent, e.g., it is `\n` for Unix and `\r\n` for Windows.

[[load-csv-headers]]
=== Headers

If the CSV file starts with a header row containing column names, each subsequent row in the file acts as a map instead of an array of strings:

.artists-with-headers.csv
[source, csv, filename="artists-with-headers.csv"]
----
Id,Name,Year
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

Indicate the header row by adding `WITH HEADERS` to the query.
This way, you can access specific fields by their corresponding column name:

.Query
[source, cypher]
----
LOAD CSV WITH HEADERS FROM 'file:///artists-with-headers.csv' AS row
CREATE (:Artist {name: row.Name, year: toInteger(row.Year)})
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

[[load-csv-field-delimiter]]
=== Field delimiter

The default field delimiter is `,`.
A CSV file may have other field delimiters:

.artists-fieldterminator.csv
[source, csv, role="noheaders", filename="artists-fieldterminator.csv"]
----
1;ABBA;1992
2;Roxette;1986
3;Europe;1979
4;The Cardigans;1992
----

In that case, change the field delimiter character by using the optional `FIELDTERMINATOR` in your query:

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists-fieldterminator.csv' AS row FIELDTERMINATOR ';'
CREATE (:Artist {name: row[1], year: toInteger(row[2])})
----

As values in this file are separated by a semicolon, a custom `FIELDTERMINATOR` is specified in the `LOAD CSV` clause.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----

[NOTE]
====
You can use the hexadecimal representation of the unicode character for the field delimiter if you prepend `{backslash}u`.
Write the encoding with four digits, for example, `{backslash}u003B` is equivalent to `;` (semicolon).
====


[[load-csv-character-escaping-and-quotes]]
=== Character escaping and quotes

If the link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings[configuration setting] `dbms.import.csv.legacy_quote_escaping` is set to `true` (the default value), `\` is used as the escape character: `"The {backslash}"Symbol{backslash}""`.
The inner double quote characters are escaped, leaving them unprocessed by `LOAD CSV`.
Only for the double quote character, you can achieve the same thing by repeating it - the escape sequence above is equivalent to `"The ""Symbol"""`.

Quoted strings are allowed in the CSV file and the quotes are dropped when reading the data with `LOAD CSV`.
To apply quotation to a string, wrap it with double quote characters: `"my_string"`.

The example below has both additional quotes around each value as well as escaped quotes in the second value:

.artists-with-escaped-char.csv
[source, csv, role="noheaders", filename="artists-with-escaped-char.csv"]
----
"1","The ""Symbol""","1992"
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists-with-escaped-char.csv' AS row
CREATE (a:Artist {name: row[1], year: toInteger(row[2])})
RETURN
  a.name AS name,
  a.year AS year,
  size(a.name) AS size
----

Note that `name` is a string and that it is wrapped in single quotes in the output below.
The third column outputs the string length as `size`.
The length only counts what is between the single quotes, but not the quotes themselves:

.Result
[role="queryresult",options="header,footer",cols="3*<m"]
|===
| name | year | size
| 'The "Symbol"' | 1992 | 12
3+d| Nodes created: 1 +
Properties set: 2 +
Labels added: 1
|===

[[load-csv-access-line-numbers-with-linenumber]]
=== Access line numbers with `linenumber()`

For certain scenarios, like debugging a problem with a CSV file, it may be useful to get the current line number that `LOAD CSV` is operating on.
The `linenumber()` function provides exactly that or `null` if called without a `LOAD CSV` context.

.artists.csv
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'file:///artists.csv' AS row
RETURN linenumber() AS number, row
----

.Result
[role="queryresult"]
----
+---------------------------------------+
| number | row                          |
+---------------------------------------+
| 1      | ["1","ABBA","1992"]          |
| 2      | ["2","Roxette","1986"]       |
| 3      | ["3","Europe","1979"]        |
| 4      | ["4","The Cardigans","1992"] |
+---------------------------------------+
4 rows
----

Also see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/functions/load-csv/#functions-linenumber[linenumber()] under LOAD CSV functions.


[[load-csv-access-the-csv-file-path-with-file]]
=== Access the CSV file path with `file()`

For certain scenarios, it may be useful to get the absolute path of the file that `LOAD CSV` is operating on.
The `file()` function provides exactly if it is called in a `LOAD CSV` context (`null` otherwise).

.artists.csv
[source, csv, role="noheaders", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher, role=test-result-skip]
----
LOAD CSV FROM 'file:///artists.csv' AS row
RETURN DISTINCT file() AS path
----

Since `LOAD CSV` can temporary download a file to process it, it is important to note that `file()` will always return the path on disk.
If `LOAD CSV` is invoked with a `file:///` URL that points to your disk `file()` will return that same path.

.Result
[role="queryresult"]
----
+------------------------------------------+
| path                                     |
+------------------------------------------+
| "/home/example/neo4j/import/artists.csv" |
+------------------------------------------+
1 row
----

Also see link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/functions/load-csv/#functions-file[file()] under LOAD CSV functions.


[[load-csv-get-csv-data-into-neo4j]]
== Get CSV data into Neo4j

[[load-csv-data-sources]]
=== CSV data sources

You can store CSV files on the database server and then access them by using a `+file:///+` URL, depending on the configuration settings.

.Configuration settings for file URLs
link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings#config_dbms.security.allow_csv_import_from_file_urls[dbms.security.allow_csv_import_from_file_urls]::
This setting determines if Cypher allows the use of `+file:///+` URLs when loading data using `LOAD CSV`.
Such URLs identify files on the filesystem of the database server.
Default is _true_.
Setting `dbms.security.allow_csv_import_from_file_urls=false` will completely disable access to the file system for `LOAD CSV`.

link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/configuration-settings#config_server.directories.import[server.directories.import]::
Sets the root directory for `+file:///+` URLs used with the Cypher `LOAD CSV` clause.
This should be set to a single directory relative to the Neo4j installation path on the database server.
All requests to load from `+file:///+` URLs are then relative to the specified directory.
The default value set in the config settings is _import_.
This is a security measure which prevents the database from accessing files outside the standard link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/file-locations[import directory],
similar to how a Unix `chroot` operates.
Setting this to an empty field allows access to all files within the Neo4j installation folder.
Commenting out this setting disables the security feature, allowing all files in the local system to be imported.
This is definitely not recommended.

File URLs are resolved relative to the `server.directories.import` directory.
For example, a file URL typically looks like `+file:///myfile.csv+` or `+file:///myproject/myfile.csv+`.

When using `+file:///+` URLs, spaces and other non-alphanumeric characters must be {url_encoded_link}.
If `server.directories.import` is set to the default value _import_, using the above URLs in `LOAD CSV` would read from _<NEO4J_HOME>/import/myfile.csv_ and _<NEO4J_HOME>/import/myproject/myfile.csv_ respectively.
*  If it is set to _/data/csv_, using the above URLs in `LOAD CSV` would read from _<NEO4J_HOME>/data/csv/myfile.csv_ and _<NEO4J_HOME>/data/csv/myproject/myfile.csv_ respectively.

.data.neo4j.com/bands/artists.csv
[source, csv, role="noheader", filename="artists.csv"]
----
1,ABBA,1992
2,Roxette,1986
3,Europe,1979
4,The Cardigans,1992
----

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/bands/artists.csv' AS row
CREATE (:Artist {name: row[1], year: toInteger(row[2])})
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 4
Properties set: 8
Labels added: 4
----


Alternatively, you can import data from a CSV file in a remote location into Neo4j.
`LOAD CSV` supports accessing CSV files via _HTTPS_, _HTTP_, and _FTP_.
`LOAD CSV` will follow _HTTP_ redirects but for security reasons it won't follow redirects which change the protocol, for example, if the redirect is going from _HTTPS_ to _HTTP_.
//Example

[NOTE]
====
The file location is relative to the import.
The config setting `server.directories.import` only applies to a local disc but doesn't to remote URLs.
====

`LOAD CSV` supports resources compressed with _gzip_ and _Deflate_.
Additionally `LOAD CSV` supports locally stored CSV files compressed with _ZIP_.
//Add links


[[load-csv-large-amounts-of-data]]
=== Large amounts of data

If the CSV file contains a significant number of rows approaching hundreds of thousands or millions, we recommend you to serialize the data processing and reduce memory overhead by doing so.
You can achieve this via link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/subqueries/subqueries-in-transactions/[multiple transactions of subqueries].
The syntax for this is `+CALL { ... } IN TRANSACTIONS+` which instructs Neo4j to commit a transaction after a number of rows.
The default is 1000 rows.
To set a different number of rows for a single transaction, append `+OF X ROWS` to `TRANSACTIONS`, where `X` is the desired number of rows.


[NOTE]
====
The query clause `CALL { ... } IN TRANSACTIONS` is only allowed in xref::introduction/cypher_neo4j.adoc#cypher-neo4j-transactions[implicit (auto-commit or `:auto`) transactions].
For more information, see xref:subqueries/subqueries-in-transactions.adoc[Subqueries in transactions].
====

The file link:https://data.neo4j.com/importing-cypher/persons.csv[_persons.csv_] contains a header line and a total of 869 lines with data about people:

.+persons.csv+
[source, csv, filename="persons.csv"]
----
person_tmdbId,bio,born,bornIn,died,person_imdbId,name,person_poster,person_url
3,"Legendary Hollywood Icon Harrison Ford was born on July 13, 1942 in Chicago, Illinois.   His family history includes a strong lineage of actors, radio personalities, and models.   Harrison attended public high school in Park Ridge, Illinois where he was a member of the school Radio Station WMTH.  Harrison worked as the lead voice for sports reporting at WMTH for several years.   Acting wasn’t a major interest to Ford until his junior year at Ripon College when he first took an acting class...",1942-07-13,"Chicago, Illinois, USA",,148,Harrison Ford,https://image.tmdb.org/t/p/w440_and_h660_face/5M7oN3sznp99hWYQ9sX0xheswWX.jpg,https://themoviedb.org/person/3
...
----

The file is more complex than the previous examples throughout this chapter.
For now, only the `name` and `born` columns are relevant.
To split the processing into chunks of 200 lines per transaction, use the following query:

.Query
[source, cypher]
----
CALL {
  LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/persons.csv' AS row
  CREATE (p:Person {name: row.name, born: row.born})
} IN TRANSACTIONS OF 200 ROWS
----

With a total of five transactions, Neo4j creates 868 `Person` nodes and sets two properties on each of them: a name and information about where the person was born.

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 868
Properties set: 1736
Labels added: 868
Transactions committed: 5
----


[[load-csv-type-cast-csv-data]]
=== Type cast CSV data

All CSV data imported via `LOAD CSV` is string data.
The file link:https://data.neo4j.com/importing-cypher/persons.csv[_persons.csv_] contains several columns which are not best represented by a string:

.+persons.csv+
[source, csv, filename="persons.csv"]
----
person_tmdbId,bio,born,bornIn,died,person_imdbId,name,person_poster,person_url
3,"Legendary Hollywood Icon Harrison Ford was born on July 13, 1942 in Chicago, Illinois.   His family history includes a strong lineage of actors, radio personalities, and models.   Harrison attended public high school in Park Ridge, Illinois where he was a member of the school Radio Station WMTH.  Harrison worked as the lead voice for sports reporting at WMTH for several years.   Acting wasn’t a major interest to Ford until his junior year at Ripon College when he first took an acting class...",1942-07-13,"Chicago, Illinois, USA",,148,Harrison Ford,https://image.tmdb.org/t/p/w440_and_h660_face/5M7oN3sznp99hWYQ9sX0xheswWX.jpg,https://themoviedb.org/person/3
...
----

Values in the columns `person_tmdbId` and `person_imdbId` are integers, while values in the `born` column are dates.
To type-cast the values while importing data, use the functions `toInteger()` and `date()`:

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/persons.csv' AS row
MERGE (p:Person {tmdbId: toInteger(row.person_tmdbId)})
SET
p.name = row.name,
p.imdbId = toInteger(row.person_imdbId),
p.born = date(row.born)
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 868
Properties set: 3472
Labels added: 868
----

Neo4j has a couple more link:{neo4j-docs-base-uri}/cypher-manual/{page-version}/values-and-types/casting-data/[type-casting functions].

[[load-csv-split-list-values]]
=== Split list values

The file link:https://data.neo4j.com/importing-cypher/movies.csv[_movies.csv_] contains a header line and a total of 94 lines with data about movies.
Two columns contain list values, `languages` and `genres`:

.+movies.csv+
[source, csv, filename="movies.csv"]
----
movieId,title,budget,countries,movie_imdbId,imdbRating,imdbVotes,languages,plot,movie_poster,released,revenue,runtime,movie_tmdbId,movie_url,year,genres
1,Toy Story,30000000.0,USA,114709,8.3,591836,English,A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.,https://image.tmdb.org/t/p/w440_and_h660_face/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg,1995-11-22,373554033.0,81,862,https://themoviedb.org/movie/862,1995,Adventure|Animation|Children|Comedy|Fantasy
2,Jumanji,65000000.0,USA,113497,6.9,198355,English|French,"When two kids find and play a magical board game, they release a man trapped for decades in it and a host of dangers that can only be stopped by finishing the game.",https://image.tmdb.org/t/p/w440_and_h660_face/vgpXmVaVyUL7GGiDeiK1mKEKzcX.jpg,1995-12-15,262797249.0,104,8844,https://themoviedb.org/movie/8844,1995,Adventure|Children|Fantasy
...
----

Both lists are separated by the character `|`.
Use the `split()` function to separate the single values and create a list while importing the data:

.Query
[source, cypher]
----
LOAD CSV FROM 'https://data.neo4j.com/importing-cypher/movies.csv' AS row
MERGE (m:Movie {movieId: toInteger(row.movieId)})
SET
m.title = row.title,
m.languages = split(row.languages, '|'),
m.genres = split(row.genres, '|')
----

.Result
[role="queryresult"]
----
+-------------------+
| No data returned. |
+-------------------+
Nodes created: 93
Properties set: 372
Labels added: 93
----


[[load-csv-create-node-labels-and-relationships]]
=== Create node labels and relationships

The next example builds upon the person and movie nodes created in <<load-csv-type-cast-csv-data>> and <<load-csv-split-list-values>>.
It makes use of the following additional CSV files:

* link:https://data.neo4j.com/importing-cypher/acted_in.csv[_acted_in.csv_]
* link:https://data.neo4j.com/importing-cypher/acted_in.csv[_directed.csv_]

_acted_in.csv_ contains data about the relationship between actors and the movies they acted in while _directed.csv_ contains data about the relationship between directors and the movies they directed.
Both actors and directors are subsets of the set of people in _persons.csv_ and refer to movies from _movies.csv_.
The connection between actors, directors and movies is established by the properties `person_tmdbId` and `movieId`:

.+movies.csv+
[source, csv, filename="acted_in.csv"]
----
movieId,person_tmdbId,role
1,12899,Slinky Dog (voice)
1,12898,Buzz Lightyear (voice)
...
----

.+movies.csv+
[source, csv, filename="directed.csv"]
----
movieId,person_tmdbId
1,7879
2,4945
...
----

The example uses data that is deliberately modeled like it could have been exported like this from a relational database.

To apply the actor node label where it is applicable and create the ACTED_IN relationship:

To apply the director node label where it is applicable and create the DIRECTED relationship:



[[load-csv-best-practices]]
== Best practices

Lipsum.


[[load-csv-inspect-imported-data-with-match]]
=== Inspect imported data with MATCH

Lipsum.


[[load-csv-prepare-clean-up-queries]]
=== Prepare clean-up queries

Lipsum.


[[load-csv-set-constraints]]
=== Set CONSTRAINTS

Lipsum.