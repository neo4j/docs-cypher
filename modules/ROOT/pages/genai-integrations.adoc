:description: Information about Neo4j's GenAI integrations.
:page-role: enterprise-edition new-5.17
:test-setup-dump: https://github.com/neo4j-graph-examples/recommendations/raw/main/data/recommendations-50.dump
include::https://raw.githubusercontent.com/neo4j-graphacademy/courses/main/asciidoc/courses/llm-fundamentals/ad.adoc[]

[[genai-integrations]]
= GenAI integrations

Neo4j's xref:indexes/semantic-indexes/vector-indexes.adoc[] and xref:functions/vector.adoc[] allow you to calculate the similarity between node and relationship properties in a graph.
A prerequisite for using these features is that vector embeddings have been set as properties of these entities.
The GenAI plugin enables the creation of such embeddings using GenAI providers.

To use the GenAI plugin you need an account and API credentials from any of the following GenAI providers: xref:genai-integrations.adoc#vertex-ai[], xref:genai-integrations.adoc#openai[], xref:genai-integrations.adoc#azure-openai[], and xref:genai-integrations.adoc#amazon-bedrock[].

To learn more about using embeddings in Neo4j, see xref:indexes/semantic-indexes/vector-indexes.adoc#embeddings[Vector indexes -> Vectors and embeddings in Neo4j].

For a hands-on guide on how to use the GenAI plugin, see link:https://neo4j.com/docs/genai/tutorials/embeddings-vector-indexes/[GenAI documentation - Embeddings & Vector Indexes Tutorial -> Create embeddings with cloud AI providers].

== Installation

The GenAI plugin is enabled by default in Neo4j Aura.

For self-managed instances, the plugin is only available on Enterprise Edition and needs to be installed.
This is done by moving the `neo4j-genai.jar` file from `/products` to `/plugins` in the Neo4j home directory, or, if you are using Docker, by starting the Docker container with the extra parameter `--env NEO4J_PLUGINS='["genai"]'`.
For more information, see link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/plugins/[Operations Manual -> Configure plugins].

[[example-graph]]
== Example graph

The examples on this page use the link:https://github.com/neo4j-graph-examples/recommendations[Neo4j movie recommendations] dataset, focusing on the `plot` and `title` properties of `Movie` nodes.

image::genai_graph.svg[width="600",role="middle"]

The graph contains 28863 nodes and 332522 relationships.
There are 9083 `Movie` nodes with a `plot` and `title` property.

To recreate the graph, download and import this link:https://github.com/neo4j-graph-examples/recommendations/blob/main/data/recommendations-embeddings-50.dump[dump file] to an empty Neo4j database (running version 5.17 or later).
Dump files can be imported for both link:{neo4j-docs-base-uri}/aura/auradb/importing/import-database/[Aura] and link:{neo4j-docs-base-uri}/operations-manual/{page-version}/backup-restore/restore-dump/[on-prem] instances.

[NOTE]
The embeddings on this are generated using link:https://platform.openai.com/docs/guides/embeddings[OpenAI] (model `text-embedding-ada-002`), producing 1536-dimensional vectors.

[[single-embedding]]
== Generate a single embedding and store it

Use the `genai.vector.encode()` function to generate a vector embedding for a single value.

.Signature for `genai.vector.encode()` label:function[]
[source,syntax]
----
genai.vector.encode(resource :: STRING, provider :: STRING, configuration :: MAP = {}) :: LIST<FLOAT>
----

* The `resource` (a `STRING`) is the object to transform into an embedding, such as a chunk text or a node/relationship property.
* The `provider` (a `STRING`) is the case-insensitive identifier of the provider to use.
See identifiers under xref:genai-integrations.adoc#ai-providers[] for supported options.
* The `configuration` (a `MAP`) contains provider-specific settings, such as which model to invoke, as well as any required API credentials.
See xref:genai-integrations.adoc#ai-providers[] for details of each supported provider.
Note that because this argument may contain sensitive data, it is obfuscated in the link:https://neo4j.com/docs/operations-manual/current/monitoring/logging/[query.log].
However, if the function call is misspelled or the query is otherwise malformed, it may be logged without being obfuscated.

[IMPORTANT]
====
This function sends one API request every time it is called, which may result in a lot of overhead in terms of both network traffic and latency.
If you want to generate many embeddings at once, use xref:genai-integrations.adoc#multiple-embeddings[].
====

Use the `db.create.setNodeVectorProperty` procedure to store an embedding to a node property.

.Signature for `db.create.setNodeVectorProperty` label:procedure[]
[source,syntax]
----
db.create.setNodeVectorProperty(node :: NODE, key :: STRING, vector :: ANY)
----

Use the `db.create.setRelationshipVectorProperty` procedure to store an embedding to a relationship property.

.Signature for `db.create.setRelationshipVectorProperty` label:procedure[] label:new[Introduced in 5.18]
[source,syntax]
----
db.create.setRelationshipVectorProperty(relationship :: RELATIONSHIP, key :: STRING, vector :: ANY)
----

* `node` or `relationship` is the entity in which the new property will be stored.
* `key` (a `STRING`) is the name of the new property containing the embedding.
* `vector` is the object containing the embedding.

The embeddings are stored as properties on nodes or relationships with the type `LIST<INTEGER | FLOAT>`.

.Create an embedding from a single property and store it
====

.Create an embedding property for the Godfather
[source,cypher,role=test-skip]
----
MATCH (m:Movie {title:'Godfather, The'})
WHERE m.plot IS NOT NULL AND m.title IS NOT NULL
WITH m, m.title || ' ' || m.plot AS titleAndPlot // <1>
WITH m, genai.vector.encode(titleAndPlot, 'OpenAI', { token: $token }) AS propertyVector // <2>
CALL db.create.setNodeVectorProperty(m, 'embedding', propertyVector) // <3>
RETURN m.embedding AS embedding
----

<1> Concatenate the `title` and `plot` of the `Movie` into a single `STRING`.
<2> Create a 1536 dimensional embedding from the `titleAndPlot`.
<3> Store the `propertyVector` as a new `embedding` property on The Godfather node.

.Result
[source, "queryresult"]
----
+----------------------------------------------------------------------------------------------------+
| embedding                                                                                          |
+----------------------------------------------------------------------------------------------------+
| [0.005239539314061403, -0.039358530193567276, -0.0005175105179660022, -0.038706034421920776, ... ] |
+----------------------------------------------------------------------------------------------------+
----

[NOTE]
This result only shows the first 4 of the 1536 numbers in the embedding.
====

[[multiple-embeddings]]
== Generating a batch of embeddings and store them

Use the `genai.vector.encodeBatch` procedure to generate many vector embeddings with a single API request.
This procedure takes a list of resources as an input, and returns the same number of result rows, instead of a single one.

[IMPORTANT]
====
This procedure attempts to generate embeddings for all supplied resources in a single API request.
Therefore, it is recommended to see the respective provider's documentation for details on, for example, the maximum number of embeddings that can be generated per request.
====

.Signature for `genai.vector.encodeBatch` label:procedure[]
[source,syntax]
----
genai.vector.encodeBatch(resources :: LIST<STRING>, provider :: STRING, configuration :: MAP = {}) :: (index :: INTEGER, resource :: STRING, vector :: LIST<FLOAT>)
----

* The `resources` (a `LIST<STRING>`) parameter is the list of objects to transform into embeddings, such as chunks of text.
* The `provider` (a `STRING`) is the case-insensitive identifier of the provider to use.
See xref:genai-integrations.adoc#ai-providers[] for supported options.
* The `configuration` (a `MAP`) specifies provider-specific settings such as which model to invoke, as well as any required API credentials.
See xref:genai-integrations.adoc#ai-providers[] for details of each supported provider.
Note that because this argument may contain sensitive data, it is obfuscated in the link:https://neo4j.com/docs/operations-manual/current/monitoring/logging/[query.log].
However, if the function call is misspelled or the query is otherwise malformed, it may be logged without being obfuscated.

Each returned row contains the following columns:

* The `index` (an `INTEGER`) is the index of the corresponding element in the input list, to aid in correlating results back to inputs.
* The `resource` (a `STRING`) is the name of the input resource.
* The `vector` (a `LIST<FLOAT>`) is the generated vector embedding for this resource.

.Create embeddings from a limited number of properties and store them
====

[source, cypher, role=test-skip]
----
MATCH (m:Movie WHERE m.plot IS NOT NULL)
WITH m
LIMIT 20
WITH collect(m) AS moviesList // <1>
WITH moviesList, [movie IN moviesList | movie.title || ': ' || movie.plot] AS batch // <2>
CALL genai.vector.encodeBatch(batch, 'OpenAI', { token: $token }) YIELD index, vector
WITH moviesList, index, vector
CALL db.create.setNodeVectorProperty(moviesList[index], 'embedding', vector) // <3>
----

<1> xref:functions/aggregating.adoc#functions-collect[Collect] all  20 `Movie` nodes into a `LIST<NODE>`.
<2> Use a xref:values-and-types/lists.adoc#cypher-list-comprehension[list comprehension] (`[]`) to extract the `title` and `plot` properties of the movies in `moviesList` into a new `LIST<STRING>`.
<3> `db.create.setNodeVectorProperty` is run for each `vector` returned by `genai.vector.encodeBatch`, and stores that vector as a property named `embedding` on the corresponding node.
====

.Create embeddings from a large number of properties and store them
====
[source, cypher, role=test-skip]
----
MATCH (m:Movie WHERE m.plot IS NOT NULL)
WITH collect(m) AS moviesList // <1>
     count(*) AS total,
     100 AS batchSize // <2>
UNWIND range(0, total, batchSize) AS batchStart // <3>
CALL (moviesList, batchStart, batchSize) { // <4>
    WITH [movie IN moviesList[batchStart .. batchStart + batchSize] | movie.title || ': ' || movie.plot] AS resources // <5>
    CALL genai.vector.encodeBatch(batch, 'OpenAI', { token: $token }) YIELD index, vector
    CALL db.create.setNodeVectorProperty(moviesList[batchStart + index], 'embedding', vector) // <6>
} IN TRANSACTIONS OF 1 ROW <7>
----

<1> xref:functions/aggregating.adoc#functions-collect[Collect] all returned `Movie` nodes into a `LIST<NODE>`.
<2> `batchSize` defines the number of nodes in `moviesList` to be processed at once.
Because vector embeddings can be very large, a larger batch size may require significantly more memory on the Neo4j server.
Too large a batch size may also exceed the provider's threshold.
<3> Process `Movie` nodes in increments of `batchSize`.
<4> A xref:subqueries/subqueries-in-transactions.adoc[`CALL` subquery] executes a separate transaction for each batch.
<5> `resources` is a list of strings, each being the concatenation of `title` and `plot` of one movie.
<6> The procedure sets `vector` as value for the property named `embedding` for the node at position `batchStart + index` in the `moviesList`.
<7> Set to `1` the amount of batches to be processed at once.

[NOTE]
This example may not scale to larger datasets, as `collect(m)` requires the whole result set to be loaded in memory.
For an alternative method more suitable to processing large amounts of data, see link:https://neo4j.com/docs/genai/tutorials/embeddings-vector-indexes/[GenAI documentation - Embeddings & Vector Indexes Tutorial -> Create embeddings with cloud AI providers].

====

[[ai-providers]]
== GenAI providers

The following GenAI providers are supported for generating vector embeddings.
Each provider has its own configuration map that can be passed to `genai.vector.encode` or `genai.vector.encodeBatch`.

[[vertex-ai]]
=== Vertex AI

* Identifier (`provider` argument): `"VertexAI"`
* https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings[Official Vertex AI documentation]

.Vertex AI provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| token
| STRING
| API access token.
| label:required[]

| projectId
| STRING
| GCP project ID.
| label:required[]

| model
| STRING
| The name of the model you want to invoke. +
 +
Supported values: +
 +

* `"textembedding-gecko@001"` label:new[Introduced in 5.17]
* `"textembedding-gecko@002"` label:new[Introduced in 5.19]
* `"textembedding-gecko@003"` label:new[Introduced in 5.19]
* `"textembedding-gecko-multilingual@001"` label:new[Introduced in 5.19]


| `"textembedding-gecko@001"`

| region
| STRING
| GCP region where to send the API requests. +
 +
Supported values: +
 +

* `"us-west1"`
* `"us-west2"`
* `"us-west3"`
* `"us-west4"`
* `"us-central1"`
* `"us-east1"`
* `"us-east4"`
* `"us-south1"`
* `"northamerica-northeast1"`
* `"northamerica-northeast2"`
* `"southamerica-east1"`
* `"southamerica-west1"`
* `"europe-west2"`
* `"europe-west1"`
* `"europe-west4"`
* `"europe-west6"`
* `"europe-west3"`
* `"europe-north1"`
* `"europe-central2"`
* `"europe-west8"`
* `"europe-west9"`
* `"europe-southwest1"`
* `"asia-south1"`
* `"asia-southeast1"`
* `"asia-southeast2"`
* `"asia-east2"`
* `"asia-east1"`
* `"asia-northeast1"`
* `"asia-northeast2"`
* `"australia-southeast1"`
* `"australia-southeast2"`
* `"asia-northeast3"`
* `"me-west1"`
| `"us-central1"`

| taskType
| STRING
| The intended downstream application (see link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#api_changes_to_models_released_on_or_after_august_2023[provider documentation]). The specified `taskType` will apply to all resources in a batch. label:new[Introduced in 5.19]
|

| title
| STRING
| The title of the document that is being encoded (see link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#api_changes_to_models_released_on_or_after_august_2023[provider documentation]). The specified `title` will apply to all resources in a batch. label:new[Introduced in 5.19]
|
|===
====

[[openai]]
=== OpenAI

* Identifier (`provider` argument): `"OpenAI"`
* https://platform.openai.com/docs/guides/embeddings[Official OpenAI documentation]

.OpenAI provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| token
| STRING
| API access token.
| label:required[]

| model
| STRING
| The name of the model you want to invoke.
| `"text-embedding-ada-002"`

| dimensions
| INTEGER
| The number of dimensions you want to reduce the vector to. Only supported for certain models.
| Model-dependent.
|===
====

[[azure-openai]]
[role=label--new-5.18]
=== Azure OpenAI

* Identifier (`provider` argument): `"AzureOpenAI"`
* https://learn.microsoft.com/en-us/azure/ai-services/openai/[Official Azure OpenAI documentation]

[NOTE]
Unlike the other providers, the model is configured when creating the deployment on Azure, and is thus not part of the configuration map.

.Azure OpenAI provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| token
| STRING
| API access token.
| label:required[]

| resource
| STRING
| The name of the resource to which the model has been deployed.
| label:required[]

| deployment
| STRING
| The name of the model deployment.
| label:required[]

| dimensions
| INTEGER
| The number of dimensions you want to reduce the vector to. Only supported for certain models.
| Model-dependent.
|===
====

[[amazon-bedrock]]
=== Amazon Bedrock

* Identifier (`provider` argument): `"Bedrock"`
* https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html[Official Bedrock documentation]

.Amazon Bedrock provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| accessKeyId
| STRING
| AWS access key ID.
| label:required[]

| secretAccessKey
| STRING
| AWS secret key.
| label:required[]

| model
| STRING
| The name of the model you want to invoke. +
 +
Supported values: +
 +

* `"amazon.titan-embed-text-v1"`
| `"amazon.titan-embed-text-v1"`

| region
| STRING
| AWS region where to send the API requests. +
 +
Supported values: +
 +

* `"us-east-1"`
* `"us-west-2"`
* `"ap-southeast-1"`
* `"ap-northeast-1"`
* `"eu-central-1"`
| `"us-east-1"`

|===
====
