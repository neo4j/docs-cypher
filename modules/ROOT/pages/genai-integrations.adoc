:description: Information about Neo4j's GenAI integrations.
:page-role: enterprise-edition new-5.17
:test-setup-dump: https://github.com/neo4j-graph-examples/recommendations/raw/main/data/recommendations-50.dump

[[genai-integrations]]
= GenAI integrations

Neo4j's xref:indexes/semantic-indexes/vector-indexes.adoc[] and xref:functions/vector.adoc[] allow users to calculate the similarity between node and relationship properties in a graph.
A precondition for using both features is that vector embeddings have been set to the properties of these entities.
The GenAI plugin enables the creation of such embeddings using GenAI providers.
To learn more about vector embeddings, see xref:indexes/semantic-indexes/vector-indexes.adoc#embeddings[Vector indexes -> Vectors and embeddings in Neo4j].

== Prerequisites and installation

To use the GenAI plugin you need an account and API credentials from any of the following GenAI providers: xref:genai-integrations.adoc#vertex-ai[], xref:genai-integrations.adoc#openai[], xref:genai-integrations.adoc#azure-openai[], and xref:genai-integrations.adoc#amazon-bedrock[].

The GenAI plugin is enabled by default in Neo4j Aura.

For self-managed instances, the plugin is only available on Enterprise Edition and needs to be installed.
This is done by moving the `neo4j-genai.jar` file from `/products` to `/plugins` in the Neo4j home directory, or, if you are using Docker, by starting the Docker container with the extra parameter `--env NEO4J_PLUGINS='["genai"]'`.
For more information, see link:{neo4j-docs-base-uri}/operations-manual/{page-version}/configuration/plugins/[Operations Manual -> Configure plugins].

[[example-graph]]
== Example graph

The examples on this page use the link:https://github.com/neo4j-graph-examples/recommendations[Neo4j movie recommendations] dataset, focusing on the `plot` property of `Movie` nodes.

image::genai_graph.svg[width="600",role="middle"]

The graph contains 28863 nodes and 332522 relationships.
There are 9083 `Movie` nodes with a `plot` property.

To recreate the graph, download and import this link:https://github.com/neo4j-graph-examples/recommendations/blob/main/data/recommendations-embeddings-50.dump[dump file] to an empty Neo4j database (running version 5.17 or later).
Dump files can be imported for both link:{neo4j-docs-base-uri}/aura/auradb/importing/import-database/[Aura] and link:{neo4j-docs-base-uri}/operations-manual/{page-version}/backup-restore/restore-dump/[on-prem] instances.

[NOTE]
The embeddings on this are generated using link:https://platform.openai.com/docs/guides/embeddings[OpenAI] (model `text-embedding-ada-002`), producing 1536-dimensional vectors.

[[single-embedding]]
== Generate a single embedding and store it

Use the `genai.vector.encode()` function to generate a vector embedding for a single value.

.Signature for `genai.vector.encode()`
[source,syntax]
----
genai.vector.encode(resource :: STRING, provider :: STRING, configuration :: MAP = {}) :: LIST<FLOAT>
----

* The `resource` (a `STRING`) is the object to transform into an embedding, such as a chunk of natural language text or a node/relationship property.
* The `provider` (a `STRING`) is the case-insensitive identifier of the provider to use.
See identifiers under xref:genai-integrations.adoc#ai-providers[] for supported options.
* The `configuration` (a `MAP`) contains provider-specific settings, such as which model to invoke, as well as any required API credentials.
See xref:genai-integrations.adoc#ai-providers[] for details of each supported provider.
Note that because this argument may contain sensitive data, it is obfuscated in the link:https://neo4j.com/docs/operations-manual/current/monitoring/logging/[_query.log_].
However, if the function call is misspelled or the query is otherwise malformed, it may be logged without being obfuscated.

[IMPORTANT]
====
This function sends one API request every time it is called, which may result in a lot of overhead in terms of both network traffic and latency.
If you want to generate many embeddings at once, use xref:genai-integrations.adoc#multiple-embeddings[].
====

Use the `db.create.setNodeVectorProperty` procedure to store an embedding to a node property.

.Signature for `db.create.setNodeVectorProperty()`
[source,syntax]
----
db.create.setNodeVectorProperty(node :: NODE, key :: STRING, vector :: ANY)
----

Use the `db.create.setRelationshipVectorProperty()` procedure to store an embedding to a relationship property.

.Signature for `db.create.setRelationshipVectorProperty()` label:new[Introduced in 5.18]
[source,syntax]
----
db.create.setRelationshipVectorProperty(relationship :: RELATIONSHIP, key :: STRING, vector :: ANY)
----

* `node` or `relationship` is the entity in which the new property will be stored.
* `key` (a `STRING`) represents the name of the new property containing the embedding.
* `vector` is the object containing the embedding.

The embeddings are represented as properties on nodes or relationships with the type `LIST<INTEGER | FLOAT>`.

.Create an embedding from a single property and store it
====

.Create an embedding property for the Godfather
[source,cypher,role=test-skip]
----
MATCH (m:Movie {title:'Godfather, The'})
WHERE m.plot IS NOT NULL AND m.title IS NOT NULL
WITH m, m.title || ' ' || m.plot AS titleAndPlot // <1>
WITH m, genai.vector.encode(titleAndPlot, "OpenAI", { token: $token }) AS propertyVector // <2>
CALL db.create.setNodeVectorProperty(m, 'embedding', propertyVector) // <3>
RETURN m.embedding AS embedding
----

<1> Concatenates the `title` and `plot` of the movie into a single `STRING`.
<2> Creates an 1536 dimensional embedding from the ``titleAndPlot`.
<3> Stores the `propertyVector` as a new `embedding` property on The Godfather node.

.Result
[source, "queryresult"]
----
| embedding
| [0.005239539314061403, -0.039358530193567276, -0.0005175105179660022, -0.038706034421920776, -0.002921548904851079, ... ]
----

[NOTE]
This result only shows the first 5 of the 1536 numbers in the embedding.
====

[[multiple-embeddings]]
== Generating a batch of embeddings and store them

Use the `genai.vector.encodeBatch()` procedure to generate many vector embeddings with a single API request.
This procedure takes a list of resources as an input, and returns the same number of result rows, instead of a single one.

Using this procedure is recommended in cases where a single large resource is split up into multiple chunks or when generating embeddings for a large number of resources.

[IMPORTANT]
====
This procedure attempts to generate embeddings for all supplied resources in a single API request.
Therefore, it is recommended to see the respective provider's documentation for details on, for example, the maximum number of embeddings that can be generated per request.
====

.Signature for `genai.vector.encodeBatch()` label:procedure[]
[source,syntax,role="noheader",indent=0]
----
genai.vector.encodeBatch(resources :: LIST<STRING>, provider :: STRING, configuration :: MAP = {}) :: (index :: INTEGER, resource :: STRING, vector :: LIST<FLOAT>)
----

* The `resources` (a `LIST<STRING>`) parameter is the list of objects to transform into embeddings, such as chunks of natural language text.
* The `provider` (a `STRING`) is the case-insensitive identifier of the provider to use.
See xref:genai-integrations.adoc#ai-providers[] for supported options.
* The `configuration` (a `MAP`) specifies provider-specific settings such as which model to invoke, as well as any required API credentials.
See xref:genai-integrations.adoc#ai-providers[] for details of each supported provider.
Note that because this argument may contain sensitive data, it is obfuscated in the link:https://neo4j.com/docs/operations-manual/current/monitoring/logging/[_query.log_].
However, if the function call is misspelled or the query is otherwise malformed, it may be logged without being obfuscated.
+
Each returned row contains the following columns:

* The `index` (an `INTEGER`) is the index of the corresponding element in the input list, to aid in correlating results back to inputs.
* The `resource` (a `STRING`) is the name of the input resource.
* The `vector` (a `LIST<FLOAT>`) is the generated vector embedding for this resource.

.Create embeddings from a limited number of properties and store them
====

[source, cypher]
----
MATCH (m:Movie)
WHERE m.plot IS NOT NULL
WITH m
LIMIT 20
WITH collect(m) AS moviesList // <1> 
WITH moviesList, [movie IN moviesList | movie.title || ': ' || movie.plot] AS batch // <2>
CALL genai.vector.encodeBatch(batch, 'OpenAI', { token: $token }) YIELD index, vector
WITH moviesList, index, vector
CALL db.create.setNodeVectorProperty(moviesList[index], 'embedding', vector) // <3>
----

<1> xref:functions/aggregating.adoc#functions-collect[Collects] a `LIST<NODE>` of 20 `Movie` nodes.
<2> Uses a xref:values-and-types/lists.adoc#cypher-list-comprehension[list comprehension] (`[]`) to extract the `title` and `plot` properties of the movies in `moviesList` into a new `LIST<STRING>`.
<3> `(moviesList[index])` retrieves the `Movie` nodes at the positions specified by `index` and ensures the correct embeddings are assigned to their corresponding movies.
====

.Create embeddings from a large number of properties and store them
====

When performing large write operations, such as batch updates, it is often necessary to use a xref:subqueries/subqueries-in-transactions.adoc[`CALL` subquery] that to execute in separate, inner transactions producing intermediate commits for each incoming row.

[source, cypher]
----
MATCH (m:Movie)
WHERE m.plot IS NOT NULL
WITH collect(m) AS moviesList
     count(*) AS total,
     100 AS batchSize // <1>
UNWIND range(0, total, batchSize) AS batchStart // <2>
CALL {
    WITH moviesList, batchStart, batchSize
    WITH moviesList, batchStart, [movie IN moviesList[batchStart .. batchStart + batchSize] | movie.title || ': ' || movie.plot] AS batch // <3>
    CALL genai.vector.encodeBatch(batch, 'OpenAI', { token: $token }) YIELD index, vector 
    CALL db.create.setNodeVectorProperty(moviesList[batchStart + index], 'embedding', vector) // <4>
} IN TRANSACTIONS OF 1 ROW <5>
----

<1>  Defines a constant value of 100 as the batch size for processing the nodes in `moviesList`.
<2> Creates groups of `Movie` nodes to processed in increments of the set `batchSize`. 
<3> Extracts the `title` and `plot` of 100 `Movie` nodes (the `batchSize`) into separate lists of strings.
<4> `moviesList[batchStart + index]` sets the `embedding` for each movie in the current batch.
Each `embedding` is matched with its `index` in the batch and assigned to the corresponding `Movie` node.
<5> Sets the amount of batches committed for each inner transaction to `1`.
Because vector embeddings can be very large, increasing the amount of rows per transaction may require significantly more memory.
====

[[ai-providers]]
== GenAI providers

The following GenAI providers are supported for generating vector embeddings.
Each provider has its own configuration map that can be passed to the `genai.vector.encode()` or `genai.vector.encodeBatch()` functions.

[[vertex-ai]]
=== Vertex AI

* Identifier (`provider` argument): `"VertexAI"`
* https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings[Official Vertex AI documentation]

.Vertex AI provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| token
| STRING
| API access token.
| label:required[]

| projectId
| STRING
| GCP project ID.
| label:required[]

| model
| STRING
| The name of the model you want to invoke. +
 +
Supported values: +
 +

* `"textembedding-gecko@001"` label:new[Introduced in 5.17]
* `"textembedding-gecko@002"` label:new[Introduced in 5.19]
* `"textembedding-gecko@003"` label:new[Introduced in 5.19]
* `"textembedding-gecko-multilingual@001"` label:new[Introduced in 5.19]


| `"textembedding-gecko@001"`

| region
| STRING
| GCP region where to send the API requests. +
 +
Supported values: +
 +

* `"us-west1"`
* `"us-west2"`
* `"us-west3"`
* `"us-west4"`
* `"us-central1"`
* `"us-east1"`
* `"us-east4"`
* `"us-south1"`
* `"northamerica-northeast1"`
* `"northamerica-northeast2"`
* `"southamerica-east1"`
* `"southamerica-west1"`
* `"europe-west2"`
* `"europe-west1"`
* `"europe-west4"`
* `"europe-west6"`
* `"europe-west3"`
* `"europe-north1"`
* `"europe-central2"`
* `"europe-west8"`
* `"europe-west9"`
* `"europe-southwest1"`
* `"asia-south1"`
* `"asia-southeast1"`
* `"asia-southeast2"`
* `"asia-east2"`
* `"asia-east1"`
* `"asia-northeast1"`
* `"asia-northeast2"`
* `"australia-southeast1"`
* `"australia-southeast2"`
* `"asia-northeast3"`
* `"me-west1"`
| `"us-central1"`

| taskType
| STRING
| The intended downstream application (see link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#api_changes_to_models_released_on_or_after_august_2023[provider documentation]). The specified `taskType` will apply to all resources in a batch. label:new[Introduced in 5.19]
| 

| title
| STRING
| The title of the document that is being encoded (see link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#api_changes_to_models_released_on_or_after_august_2023[provider documentation]). The specified `title` will apply to all resources in a batch. label:new[Introduced in 5.19]
| 
|===
====

[[openai]]
=== OpenAI

* Identifier (`provider` argument): `"OpenAI"`
* https://platform.openai.com/docs/guides/embeddings[Official OpenAI documentation]

.OpenAI provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| token
| STRING
| API access token.
| label:required[]

| model
| STRING
| The name of the model you want to invoke.
| `"text-embedding-ada-002"`

| dimensions
| INTEGER
| The number of dimensions you want to reduce the vector to. Only supported for certain models.
| Model-dependent.
|===
====

[[azure-openai]]
[role=label--new-5.18]
=== Azure OpenAI

* Identifier (`provider` argument): `"AzureOpenAI"`
* https://learn.microsoft.com/en-us/azure/ai-services/openai/[Official Azure OpenAI documentation]

Note that, unlike the other providers, the model is configured when creating the deployment on Azure, and is thus not part of the configuration map.

.Azure OpenAI provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| token
| STRING
| API access token.
| label:required[]

| resource
| STRING
| The name of the resource to which the model has been deployed.
| label:required[]

| deployment
| STRING
| The name of the model deployment.
| label:required[]

| dimensions
| INTEGER
| The number of dimensions you want to reduce the vector to. Only supported for certain models.
| Model-dependent.
|===
====

[[amazon-bedrock]]
=== Amazon Bedrock

* Identifier (`provider` argument): `"Bedrock"`
* https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html[Official Bedrock documentation]

.Amazon Bedrock provider details
[%collapsible]
====
.Configuration map
[%header,cols="1m,1m,3a,2"]
|===
| Key | Type | Description | Default

| accessKeyId
| STRING
| AWS access key ID.
| label:required[]

| secretAccessKey
| STRING
| AWS secret key.
| label:required[]

| model
| STRING
| The name of the model you want to invoke. +
 +
Supported values: +
 +
 
* `"amazon.titan-embed-text-v1"`
| `"amazon.titan-embed-text-v1"`

| region
| STRING
| AWS region where to send the API requests. +
 +
Supported values: +
 +
 
* `"us-east-1"`
* `"us-west-2"`
* `"ap-southeast-1"`
* `"ap-northeast-1"`
* `"eu-central-1"`
| `"us-east-1"`

|===
====